{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JQMyebI0OLqv"
   },
   "source": [
    "# **Bioinformatics Project - Computational Drug Discovery [Part 4] Classification Models Building**\n",
    "\n",
    "**MOUNSIF EL ATOUCH**\n",
    "\n",
    "In this Jupyter notebook, we will be building a machine learning model using the ChEMBL bioactivity data.\n",
    "\n",
    "In **Part 4**, we will be building classification models\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bMhHx_CmOTPD"
   },
   "source": [
    "## **Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "o-MeyPj2tsrb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "seed = 42\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from scipy import interp\n",
    "from math import *\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "UqPr6idQPgiF"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "pyKg-HQhtsre"
   },
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "KW7CP2Hwtsre"
   },
   "outputs": [],
   "source": [
    "def print_auc(clf, X_train, y_train, X_test, y_test, model_name) :\n",
    "    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "    fpr, tpr, thr = roc_curve(y_test,  y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    #plt.plot(fpr, tpr, label=model_name+\" auc=\"+str(roc_auc))\n",
    "    #plt.legend(loc=4)\n",
    "    #plt.title(\"ROC curve\")\n",
    "\n",
    "    #plt.show()\n",
    "    # Data to plot precision - recall curve\n",
    "    precision, recall, thresholds_log = precision_recall_curve(y_test, y_pred_proba)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    \n",
    "    #plt.plot(recall, precision, label=model_name+\" auc_prc=\"+str(auc_precision_recall))\n",
    "    #plt.xlabel(\"Recall\")\n",
    "    #plt.ylabel(\"Precision\")\n",
    "    #plt.legend(loc=4)\n",
    "    #plt.title(\"Precision-Recall Curve\")\n",
    "\n",
    "    #plt.show()\n",
    "    precision_sc=precision_score(y_test, clf.predict(X_test), average=None)\n",
    "    recall_sc = recall_score(y_test, clf.predict(X_test), average=None)\n",
    "    test_score = accuracy_score(y_test, clf.predict(X_test)) * 100\n",
    "    train_score = accuracy_score(y_train, clf.predict(X_train)) * 100\n",
    "    f1 = f1_score(y_test, clf.predict(X_test))\n",
    "    print_score(clf, X_train, y_train, X_test, y_test, train=True)\n",
    "    print_score(clf, X_train, y_train, X_test, y_test, train=False)\n",
    "    metriques = {\"fpr\" : fpr, \"recall_sc\" : recall_sc, \"precision_sc\" : precision_sc, \"tpr\" : tpr,\n",
    "                 \"test_score\" : test_score, \"train_score\" : train_score, \"f1\" : f1,\n",
    "                 \"auc_pr\" : auc_precision_recall, \"auc\": roc_auc}\n",
    "    return metriques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nLtPCIKXtsrf"
   },
   "source": [
    "## **Load the data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "absK-NcdwMa9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-06-03 01:23:54--  https://raw.githubusercontent.com/mounsifelatouch/cdd/master/data/bioactivity_data_PubchemFingerprinter.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1154424 (1.1M) [text/plain]\n",
      "Saving to: 'bioactivity_data_PubchemFingerprinter.csv'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4%  149K 7s\n",
      "    50K .......... .......... .......... .......... ..........  8% 11.4K 49s\n",
      "   100K .......... .......... .......... .......... .......... 13% 9.17K 66s\n",
      "   150K .......... .......... .......... .......... .......... 17% 14.8K 63s\n",
      "   200K .......... .......... .......... .......... .......... 22% 30.5K 53s\n",
      "   250K .......... .......... .......... .......... .......... 26% 30.9K 46s\n",
      "   300K .......... .......... .......... .......... .......... 31% 26.0K 42s\n",
      "   350K .......... .......... .......... .......... .......... 35% 27.3K 37s\n",
      "   400K .......... .......... .......... .......... .......... 39% 25.0K 34s\n",
      "   450K .......... .......... .......... .......... .......... 44% 28.2K 31s\n",
      "   500K .......... .......... .......... .......... .......... 48% 38.6K 27s\n",
      "   550K .......... .......... .......... .......... .......... 53% 13.5K 26s\n",
      "   600K .......... .......... .......... .......... .......... 57% 13.6K 24s\n",
      "   650K .......... .......... .......... .......... .......... 62% 37.1K 21s\n",
      "   700K .......... .......... .......... .......... .......... 66% 85.3K 18s\n",
      "   750K .......... .......... .......... .......... .......... 70% 39.9K 15s\n",
      "   800K .......... .......... .......... .......... .......... 75% 39.6K 12s\n",
      "   850K .......... .......... .......... .......... .......... 79% 20.1K 10s\n",
      "   900K .......... .......... .......... .......... .......... 84% 43.1K 8s\n",
      "   950K .......... .......... .......... .......... .......... 88% 37.5K 5s\n",
      "  1000K .......... .......... .......... .......... .......... 93% 47.5K 3s\n",
      "  1050K .......... .......... .......... .......... .......... 97% 34.7K 1s\n",
      "  1100K .......... .......... .......                         100% 30.7K=46s\n",
      "\n",
      "2023-06-03 01:24:41 (24.6 KB/s) - 'bioactivity_data_PubchemFingerprinter.csv' saved [1154424/1154424]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/mounsifelatouch/cdd/master/data/bioactivity_data_PubchemFingerprinter.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "VqaS8i8ytsrh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>PubchemFP9</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows Ã— 882 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  PubchemFP4  PubchemFP5  \\\n",
       "0             1           1           0           0           0           0   \n",
       "1             1           1           0           0           0           0   \n",
       "2             1           1           1           0           0           0   \n",
       "3             1           1           1           0           0           0   \n",
       "4             1           1           0           0           0           0   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "643           1           1           1           0           0           0   \n",
       "644           1           1           1           0           0           0   \n",
       "645           1           1           1           0           0           0   \n",
       "646           1           1           1           0           0           0   \n",
       "647           1           1           0           0           0           0   \n",
       "\n",
       "     PubchemFP6  PubchemFP7  PubchemFP8  PubchemFP9  ...  PubchemFP872  \\\n",
       "0             0           0           0           1  ...             0   \n",
       "1             0           0           0           1  ...             0   \n",
       "2             0           0           0           1  ...             0   \n",
       "3             0           0           0           1  ...             0   \n",
       "4             0           0           0           1  ...             0   \n",
       "..          ...         ...         ...         ...  ...           ...   \n",
       "643           0           0           0           1  ...             0   \n",
       "644           0           0           0           1  ...             0   \n",
       "645           0           0           0           1  ...             0   \n",
       "646           0           0           0           1  ...             0   \n",
       "647           0           0           0           1  ...             0   \n",
       "\n",
       "     PubchemFP873  PubchemFP874  PubchemFP875  PubchemFP876  PubchemFP877  \\\n",
       "0               0             0             0             0             0   \n",
       "1               0             0             0             0             0   \n",
       "2               0             0             0             0             0   \n",
       "3               0             0             0             0             0   \n",
       "4               0             0             0             0             0   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "643             0             0             0             0             0   \n",
       "644             0             0             0             0             0   \n",
       "645             0             0             0             0             0   \n",
       "646             0             0             0             0             0   \n",
       "647             0             0             0             0             0   \n",
       "\n",
       "     PubchemFP878  PubchemFP879  PubchemFP880  Activity  \n",
       "0               0             0             0         0  \n",
       "1               0             0             0         0  \n",
       "2               0             0             0         0  \n",
       "3               0             0             0         0  \n",
       "4               0             0             0         0  \n",
       "..            ...           ...           ...       ...  \n",
       "643             0             0             0         0  \n",
       "644             0             0             0         0  \n",
       "645             0             0             0         0  \n",
       "646             0             0             0         0  \n",
       "647             0             0             0         0  \n",
       "\n",
       "[648 rows x 882 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bioactivity_data_PubchemFingerprinter.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dYZ6-KJNtsrh"
   },
   "source": [
    "## **Input features**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gQVFKOCetsri"
   },
   "source": [
    "### **Input features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "rPa_Zev-tsri"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Activity', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9fJkeKehtsri"
   },
   "source": [
    "### **Output features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "JlkQHZzKtsri"
   },
   "outputs": [],
   "source": [
    "y = df['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "EHo7xgLmtsrj"
   },
   "outputs": [],
   "source": [
    "# count the number of instances in each class\n",
    "counts = y.value_counts()\n",
    "\n",
    "# calculate the ratio of the negative class to the positive class\n",
    "imbalance_ratio = counts[0] / counts[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_fdRGAIltsrj"
   },
   "source": [
    "### **Let's examine the data dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "GZFGmQwRtsrj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((648, 881), (648,))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove low variance features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels) (1.23.5)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from packaging>=21.3->statsmodels) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0->statsmodels) (2022.6)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = forward_selection(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-svjbOfutsrk"
   },
   "source": [
    "## **Data split (80/20 ratio)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jF52tbMYw1z5"
   },
   "outputs": [],
   "source": [
    "n = np.arange(len(X))\n",
    "idx_train, idx_test = train_test_split(n, test_size=.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMw13QDQtsrk"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X.loc[idx_train], y.loc[idx_train]\n",
    "X_test, y_test = X.loc[idx_test], y.loc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vej1D8zrtsrk"
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "N4rFAzWytsrl"
   },
   "source": [
    "## **Data balancing**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NyZW_Nd_tsrl"
   },
   "source": [
    "### **Random Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RI8yGfqutsrl"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# create an oversampler object with a 1:1 ratio of positive to negative samples\n",
    "ros = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# fit and apply the oversampler to the training data\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gwO-v_JItsrl"
   },
   "source": [
    "### **SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MVK0C2ptsrl"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Perform oversampling on the minority class in the training set\n",
    "sm = SMOTE(random_state=seed)\n",
    "\n",
    "# fit and apply the oversampler to the training data\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4OQ3xLJ0tsrl"
   },
   "source": [
    "### **ADASYN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLwXSD8Ptsrm"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Perform oversampling on the minority class in the training set\n",
    "adasyn = ADASYN(random_state=seed)\n",
    "\n",
    "# fit and apply the oversampler to the training data\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UF-kp8rLhvNB"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5K8LAAYtsrm"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQvl_xl1AkzX"
   },
   "outputs": [],
   "source": [
    "n_samples, n_classes = X_train.shape[0], 2\n",
    "class_weights = dict(zip(np.unique(y_train), n_samples / (n_classes * np.bincount(y_train))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_LJzaixXHFXl"
   },
   "source": [
    "# **GridSearchCV**\n",
    "* cv = 10\n",
    "* *`'balanced_accuracy'`* as a scoring metric to deal with imbalanced datasets. It is defined as the average of recall obtained on each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "a61e7KdJtsrm"
   },
   "source": [
    "## **ExtraTreesClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwLIZGHytsrm"
   },
   "outputs": [],
   "source": [
    "clf1 = ExtraTreesClassifier(random_state=seed, class_weight='balanced')\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'max_depth': [10, 25, 50, 100],\n",
    "              'max_features': [int(sqrt(X.shape[1])), int(log2(X.shape[1]))],\n",
    "              'min_samples_split' : [2, 5, 10], \n",
    "              'min_samples_leaf' : [1, 5, 10],\n",
    "              'class_weight' : ['balanced', None]}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf1, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = ExtraTreesClassifier(**grid_search.best_params_, random_state=seed)\n",
    "model1 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf1 = print_auc(model1, X_train, y_train, X_test, y_test, 'ExtraTreesClassifier')\n",
    "df1 = pd.DataFrame(data=[['ExtraTreesClassifier', clf1['f1'], clf1['auc'], clf1['auc_pr'], clf1['recall_sc'][0], clf1['recall_sc'][1], clf1['precision_sc'][0], clf1['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df1.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QQCRXaiWtsrp"
   },
   "source": [
    "## **XGBClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = xgb.XGBClassifier(objective='binary:logistic')\n",
    "param_grid = {'learning_rate' : [0.01, 0.1, 0.2],\n",
    "              'max_depth' : [3, 10, 25],\n",
    "              'gamma' : [0.1, 0.5, 1.0],\n",
    "              'subsample': [0.5, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.5, 0.8, 1.0],\n",
    "              'scale_pos_weight': [1, imbalance_ratio]}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf2, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = xgb.XGBClassifier(**grid_search.best_params_, objective='binary:logistic')\n",
    "model2 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf2 = print_auc(model2, X_train, y_train, X_test, y_test, 'XGBClassifier')\n",
    "df2 = pd.DataFrame(data=[['XGBClassifier', clf2['f1'], clf2['auc'], clf2['auc_pr'], clf2['recall_sc'][0], clf2['recall_sc'][1], clf2['precision_sc'][0], clf2['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df2.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AdaBoostClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zae2H2ZiJ6fg"
   },
   "outputs": [],
   "source": [
    "clf3 = AdaBoostClassifier(random_state=seed)\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "              'learning_rate': [0.01, 0.1, 0.2],\n",
    "              'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=3)]}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf3, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = AdaBoostClassifier(**grid_search.best_params_, random_state=seed)\n",
    "model3 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf3 = print_auc(model3, X_train, y_train, X_test, y_test, 'AdaBoostClassifier')\n",
    "df3 = pd.DataFrame(data=[['AdaBoostClassifier', clf3['f1'], clf3['auc'], clf3['auc_pr'], clf3['recall_sc'][0], clf3['recall_sc'][1], clf3['precision_sc'][0], clf3['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df3.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AFc-ALhpSAJ-"
   },
   "source": [
    "## **DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UXnbmeSSKP7"
   },
   "outputs": [],
   "source": [
    "clf4 = DecisionTreeClassifier(random_state=seed)\n",
    "param_grid = {'min_samples_split': [2, 5, 10, 20],\n",
    "              'max_depth': [2, 3, 4, 5, None],\n",
    "              'min_samples_leaf': [1, 2, 4, 8],\n",
    "              'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "              'max_features': ['auto', int(sqrt(X.shape[1])), int(log2(X.shape[1]))]}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf4, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = DecisionTreeClassifier(**grid_search.best_params_, random_state=seed)\n",
    "model4 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf4 = print_auc(model4, X_train, y_train, X_test, y_test, 'DecisionTreeClassifier')\n",
    "df4 = pd.DataFrame(data=[['DecisionTreeClassifier', clf4['f1'], clf4['auc'], clf4['auc_pr'], clf4['recall_sc'][0], clf4['recall_sc'][1], clf4['precision_sc'][0], clf4['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df4.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KIIIZFOcVuhP"
   },
   "source": [
    "## **GaussianNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkL_8QXOX8fO"
   },
   "outputs": [],
   "source": [
    "clf5 = GaussianNB()\n",
    "param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf5, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = GaussianNB(**grid_search.best_params_)\n",
    "model5 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf5 = print_auc(model5, X_train, y_train, X_test, y_test, 'GaussianNB')\n",
    "df5 = pd.DataFrame(data=[['GaussianNB', clf5['f1'], clf5['auc'], clf5['auc_pr'], clf5['recall_sc'][0], clf5['recall_sc'][1], clf5['precision_sc'][0], clf5['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df5.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qj2YVJ9XZcIY"
   },
   "source": [
    "## **LGBMClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqzDidPvZbB9"
   },
   "outputs": [],
   "source": [
    "clf6 = lgb.LGBMClassifier()\n",
    "param_grid = {'num_leaves': [10, 20, 30],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'learning_rate': [0.01, 0.1],\n",
    "              'n_estimators': [50, 100, 200],\n",
    "              'min_child_samples': [10, 20, 30],\n",
    "              'subsample': [0.8, 0.9, 1.0],\n",
    "              'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "              'class_weight' : ['balanced', None]}\n",
    "         \n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf6, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = lgb.LGBMClassifier(**grid_search.best_params_)\n",
    "model6 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf6 = print_auc(model6, X_train, y_train, X_test, y_test, 'LGBMClassifier')\n",
    "df6 = pd.DataFrame(data=[['LGBMClassifier', clf6['f1'], clf6['auc'], clf6['auc_pr'], clf6['recall_sc'][0], clf6['recall_sc'][1], clf6['precision_sc'][0], clf6['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df6.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tAN365LxheXY"
   },
   "source": [
    "## **KNeighborsClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QTUZs-HhtEf"
   },
   "outputs": [],
   "source": [
    "clf7 = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [3, 5, 7],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'p': [1, 2],\n",
    "              'algorithm': ['brute'],\n",
    "              'leaf_size': [10, 30, 50]}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf7, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = KNeighborsClassifier(**grid_search.best_params_)\n",
    "model7 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf7 = print_auc(model7, X_train, y_train, X_test, y_test, 'KNeiborsClassifier')\n",
    "df7 = pd.DataFrame(data=[['KNeiborsClassifier', clf7['f1'], clf7['auc'], clf7['auc_pr'], clf7['recall_sc'][0], clf7['recall_sc'][1], clf7['precision_sc'][0], clf7['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df7.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QHWcEGBUrLFm"
   },
   "source": [
    "## **RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFkOjSCzrTaT"
   },
   "outputs": [],
   "source": [
    "clf8 = RandomForestClassifier(random_state=seed)\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': ['sqrt', 'log2'],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf8, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = RandomForestClassifier(**grid_search.best_params_, random_state=seed)\n",
    "model8 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf8 = print_auc(model8, X_train, y_train, X_test, y_test, 'RandomForestClassifier')\n",
    "df8 = pd.DataFrame(data=[['RandomForestClassifier', clf8['f1'], clf8['auc'], clf8['auc_pr'], clf8['recall_sc'][0], clf8['recall_sc'][1], clf8['precision_sc'][0], clf8['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df8.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "naDCYmAFvWpV"
   },
   "source": [
    "## **SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkoMquuFvrwg"
   },
   "outputs": [],
   "source": [
    "clf9 = SVC(probability=True)\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'kernel': ['linear', 'poly', 'rbf'],\n",
    "              'degree': [2, 3, 4],\n",
    "              'gamma': ['scale', 'auto'],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf9, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = SVC(**grid_search.best_params_, probability=True)\n",
    "model9 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf9 = print_auc(model9, X_train, y_train, X_test, y_test, 'SVM')\n",
    "df9 = pd.DataFrame(data=[['SVM', clf9['f1'], clf9['auc'], clf9['auc_pr'], clf9['recall_sc'][0], clf9['recall_sc'][1], clf9['precision_sc'][0], clf9['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df9.style.hide_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "trgFN6rWy8Ws"
   },
   "source": [
    "## **LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jByhlu6xzBkq"
   },
   "outputs": [],
   "source": [
    "clf10 = LogisticRegression()\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.1, 1, 10],\n",
    "              'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag'],\n",
    "              'max_iter': [100, 200, 500],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "\n",
    "grid_search = GridSearchCV(clf10, param_grid=param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params.append(grid_search.best_params_)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best mean cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "clf_best = LogisticRegression(**grid_search.best_params_, random_state=seed)\n",
    "model10 = clf_best.fit(X_train, y_train)\n",
    "\n",
    "clf10 = print_auc(model10, X_train, y_train, X_test, y_test, 'LogisticRegression')\n",
    "df10 = pd.DataFrame(data=[['LogisticRegression', clf10['f1'], clf10['auc'], clf10['auc_pr'], clf10['recall_sc'][0], clf10['recall_sc'][1], clf10['precision_sc'][0], clf10['precision_sc'][1]]], \n",
    "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
    "df10.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idFcRaGqEizz"
   },
   "outputs": [],
   "source": [
    "df = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10]\n",
    "df_finale = pd.concat(df)\n",
    "df_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finale.to_csv('df_finale.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEIYI-NQMhy-"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "plt.plot(clf6[\"fpr\"], clf6[\"tpr\"], label=\"LGBMClassifier, auc=\"+str(clf10[\"auc\"]))\n",
    "plt.plot(clf9[\"fpr\"], clf9[\"tpr\"], label=\"SVM, auc=\"+str(clf2[\"auc\"]))\n",
    "plt.plot(clf5[\"fpr\"], clf5[\"tpr\"], label=\"GaussianNB, auc=\"+str(clf3[\"auc\"]))\n",
    "plt.plot(clf1[\"fpr\"], clf1[\"tpr\"], label=\"ExtraTrees, auc=\"+str(clf6[\"auc\"]))\n",
    "plt.plot(clf7[\"fpr\"], clf7[\"tpr\"], label=\"KNN, auc=\"+str(clf5[\"auc\"]))\n",
    "plt.plot(clf4[\"fpr\"], clf4[\"tpr\"], label=\"DT, auc=\"+str(clf8[\"auc\"]))\n",
    "plt.plot(clf10[\"fpr\"], clf10[\"tpr\"], label=\"LR, auc=\"+str(clf9[\"auc\"]))\n",
    "plt.plot(clf8[\"fpr\"], clf8[\"tpr\"], label=\"RF, auc=\"+str(clf4[\"auc\"]))\n",
    "plt.plot(clf3[\"fpr\"], clf3[\"tpr\"], label=\"AdaBoost, auc=\"+str(clf7[\"auc\"]))\n",
    "plt.plot(clf2[\"fpr\"], clf2[\"tpr\"], label=\"XGB, auc=\"+str(clf2[\"auc\"]))\n",
    "\n",
    "plt.xlabel(\"tpr\")\n",
    "plt.ylabel(\"fpr\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_confusion_matrix(best_model, fingerprints_test, bioactivity_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(best_model, 'best_model.sav')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
