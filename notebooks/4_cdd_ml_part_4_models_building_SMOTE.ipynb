{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mounsifelatouch/cdd/blob/master/notebooks/4_cdd_ml_part_4_models_building_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQMyebI0OLqv"
      },
      "source": [
        "# **Bioinformatics Project - Computational Drug Discovery [Part 4] Classification Models Building**\n",
        "\n",
        "**MOUNSIF EL ATOUCH**\n",
        "\n",
        "In this Jupyter notebook, we will be building a machine learning model using the ChEMBL bioactivity data.\n",
        "\n",
        "In **Part 4**, we will be building classification models\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMhHx_CmOTPD"
      },
      "source": [
        "## **Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-MeyPj2tsrb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.spatial.distance import *\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "seed = 42\n",
        "\n",
        "from sklearn.model_selection import *\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.metrics import *\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqPr6idQPgiF"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import lightgbm as lgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.svm import SVC  \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj2ZDXttCmhT"
      },
      "source": [
        "## **Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyKg-HQhtsre"
      },
      "outputs": [],
      "source": [
        "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
        "    if train:\n",
        "        pred = clf.predict(X_train)\n",
        "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
        "        print(\"Train Result:\\n================================================\")\n",
        "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
        "        \n",
        "    elif train==False:\n",
        "        pred = clf.predict(X_test)\n",
        "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
        "        print(\"Test Result:\\n================================================\")        \n",
        "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW7CP2Hwtsre"
      },
      "outputs": [],
      "source": [
        "def print_auc(clf, X_train, y_train, X_test, y_test, model_name) :\n",
        "    \n",
        "    clf = clf.fit(X_train, y_train)\n",
        "    y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
        "    fpr, tpr, thr = roc_curve(y_test,  y_pred_proba)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=model_name+\" auc=\"+str(roc_auc))\n",
        "    plt.legend(loc=4)\n",
        "    plt.title(\"ROC curve\")\n",
        "\n",
        "    plt.show()\n",
        "    # Data to plot precision - recall curve\n",
        "    precision, recall, thresholds_log = precision_recall_curve(y_test, y_pred_proba)\n",
        "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
        "    auc_precision_recall = auc(recall, precision)\n",
        "    \n",
        "    plt.plot(recall, precision, label=model_name+\" auc_prc=\"+str(auc_precision_recall))\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.legend(loc=4)\n",
        "    plt.title(\"Precision-Recall Curve\")\n",
        "\n",
        "    plt.show()\n",
        "    precision_sc = precision_score(y_test, clf.predict(X_test), average=None)\n",
        "    recall_sc = recall_score(y_test, clf.predict(X_test), average=None)\n",
        "    test_score = accuracy_score(y_test, clf.predict(X_test)) * 100\n",
        "    train_score = accuracy_score(y_train, clf.predict(X_train)) * 100\n",
        "    f1 = f1_score(y_test, clf.predict(X_test))\n",
        "    print_score(clf, X_train, y_train, X_test, y_test, train=True)\n",
        "    print_score(clf, X_train, y_train, X_test, y_test, train=False)\n",
        "    metriques = {\"fpr\" : fpr, \"recall_sc\" : recall_sc, \"precision_sc\" : precision_sc, \"tpr\" : tpr,\n",
        "                 \"test_score\" : test_score, \"train_score\" : train_score, \"f1\" : f1,\n",
        "                 \"auc_pr\" : auc_precision_recall, \"auc\": roc_auc}\n",
        "    return metriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCC4nkb2CmhV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    # generate the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # create a heatmap of the confusion matrix\n",
        "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "\n",
        "    # set the axis labels\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLtPCIKXtsrf"
      },
      "source": [
        "## **Load the data set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "absK-NcdwMa9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "! wget https://raw.githubusercontent.com/mounsifelatouch/cdd/master/data/bioactivity_data_PubchemFingerprinter.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqaS8i8ytsrh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('bioactivity_data_PubchemFingerprinter.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['activity'].value_counts()"
      ],
      "metadata": {
        "id": "8gVrkkr4kagC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYZ6-KJNtsrh"
      },
      "source": [
        "## **Input features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQVFKOCetsri"
      },
      "source": [
        "### **Input features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPa_Zev-tsri"
      },
      "outputs": [],
      "source": [
        "X = df.drop('activity', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fJkeKehtsri"
      },
      "source": [
        "### **Output features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlkQHZzKtsri"
      },
      "outputs": [],
      "source": [
        "y = df['activity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHo7xgLmtsrj"
      },
      "outputs": [],
      "source": [
        "# count the number of instances in each class\n",
        "counts = y.value_counts()\n",
        "\n",
        "# calculate the ratio of the negative class to the positive class\n",
        "imbalance_ratio = counts[0] / counts[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fdRGAIltsrj"
      },
      "source": [
        "### **Let's examine the data dimension**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZFGmQwRtsrj"
      },
      "outputs": [],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIASfTL3CmhY"
      },
      "source": [
        "### **Remove low variance features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkVYnr6GCmhY"
      },
      "outputs": [],
      "source": [
        "# Create a VarianceThreshold object\n",
        "selector = VarianceThreshold(threshold=.01)\n",
        "\n",
        "# Fit the selector to the data and transform the data\n",
        "selector.fit_transform(X)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_features = X.columns[selected_indices]\n",
        "\n",
        "X = X[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-AOwwPOCmhY"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-svjbOfutsrk"
      },
      "source": [
        "## **Data split (80/20 ratio)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF52tbMYw1z5"
      },
      "outputs": [],
      "source": [
        "n = np.arange(len(X))\n",
        "idx_train, idx_test = train_test_split(n, stratify=y, test_size=.2, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMw13QDQtsrk"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = X.loc[idx_train], y.loc[idx_train]\n",
        "X_test, y_test = X.loc[idx_test], y.loc[idx_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vej1D8zrtsrk"
      },
      "outputs": [],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "G76AK1RjJEii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF-kp8rLhvNB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data balancing**"
      ],
      "metadata": {
        "id": "f6DDGxX2JJWk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwO-v_JItsrl"
      },
      "source": [
        "### **SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MVK0C2ptsrl"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Perform oversampling on the minority class in the training set\n",
        "sm = SMOTE(random_state=seed)\n",
        "\n",
        "# fit and apply the oversampler to the training data\n",
        "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nn6UpJfCmh5"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_sm.reset_index(drop=True)\n",
        "y_train = y_train_sm.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIDuhAuBCmh5"
      },
      "outputs": [],
      "source": [
        "n_samples, n_classes = X_train.shape[0], 2\n",
        "class_weights = dict(zip(np.unique(y_train), n_samples / (n_classes * np.bincount(y_train))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFlUk-yUCmh5"
      },
      "source": [
        "# **RandomizedSearchCV**\n",
        "* cv = 5\n",
        "* n_iter = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUzW2gxFCmh5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zVu_ZGTCmh6"
      },
      "outputs": [],
      "source": [
        "best_params = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXv4h6UKCmh6"
      },
      "source": [
        "## **ExtraTreesClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmjsjkX5Cmh6"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'n_estimators': randint(100, 1000),\n",
        "              'max_depth': randint(10, 100),\n",
        "              'max_features': ['sqrt', 'log2'],\n",
        "              'min_samples_split' : randint(2, 10), \n",
        "              'min_samples_leaf' : randint(1, 10),\n",
        "              'class_weight' : ['balanced', None, class_weights]}\n",
        "\n",
        "# Create the ExtraTreesClassifier model\n",
        "clf1 = ExtraTreesClassifier(random_state=seed)\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf1, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4hXVduuCmh6"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = ExtraTreesClassifier(**random_search.best_params_, random_state=seed)\n",
        "model1 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf1 = print_auc(model1, X_train, y_train, X_test, y_test, 'ExtraTreesClassifier')\n",
        "df1 = pd.DataFrame(data=[['ExtraTreesClassifier', clf1['f1'],  clf1['auc'], clf1['auc_pr'], clf1['recall_sc'][0], clf1['recall_sc'][1], clf1['precision_sc'][0], clf1['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df1.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFcBbRBWCmh6"
      },
      "source": [
        "## **XGBClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2ngA2hwCmh7"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'learning_rate' : uniform(1e-5, 1),\n",
        "              'max_depth' : randint(3, 25),\n",
        "              'gamma' : uniform(0.1, 1),\n",
        "              'subsample': uniform(0.5, 1),\n",
        "              'colsample_bytree': uniform(0.5, 1),\n",
        "              'scale_pos_weight': [1, imbalance_ratio]}\n",
        "\n",
        "# Create the XGBClassifier model\n",
        "clf2 = xgb.XGBClassifier(objective='binary:logistic')\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf2, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9MnfBvsCmh7"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = xgb.XGBClassifier(**random_search.best_params_, random_state=seed)\n",
        "model2 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf2 = print_auc(model2, X_train, y_train, X_test, y_test, 'XGBClassifier')\n",
        "df2 = pd.DataFrame(data=[['XGBClassifier', clf2['f1'], clf2['auc'], clf2['auc_pr'], clf2['recall_sc'][0], clf2['recall_sc'][1], clf2['precision_sc'][0], clf2['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df2.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27QoZOQkCmh7"
      },
      "source": [
        "## **AdaBoostClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDjg0ahiCmh7"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'n_estimators': randint(50, 200),\n",
        "              'learning_rate': uniform(1e-5, 1),\n",
        "              'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=3)]}\n",
        "\n",
        "# Create the AdaBoostClassifier model\n",
        "clf3 = AdaBoostClassifier(random_state=seed)\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf3, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvUsjt2_Cmh7"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = AdaBoostClassifier(**random_search.best_params_, random_state=seed)\n",
        "model3 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf3 = print_auc(model3, X_train, y_train, X_test, y_test, 'AdaBoostClassifier')\n",
        "df3 = pd.DataFrame(data=[['AdaBoostClassifier', clf3['f1'], clf3['auc'], clf3['auc_pr'], clf3['recall_sc'][0], clf3['recall_sc'][1], clf3['precision_sc'][0], clf3['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df3.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LJKRDKfCmh7"
      },
      "source": [
        "## **DecisionTreeClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpE2ZIeZCmh8"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'min_samples_split': randint(2, 20),\n",
        "              'max_depth': randint(3, 10),\n",
        "              'min_samples_leaf': randint(2, 10),\n",
        "              'criterion' : ['gini', 'entropy', 'log_loss'],\n",
        "              'max_features': ['auto', 'sqrt', 'log2']}\n",
        "\n",
        "# Create the DecisionTreeClassifierr model\n",
        "clf4 = DecisionTreeClassifier(random_state=seed)\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf4, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJkWspdqCmh8"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = DecisionTreeClassifier(**random_search.best_params_, random_state=seed)\n",
        "model4 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf4 = print_auc(model4, X_train, y_train, X_test, y_test, 'DecisionTreeClassifier')\n",
        "df4 = pd.DataFrame(data=[['DecisionTreeClassifier', clf4['f1'], clf4['auc'], clf4['auc_pr'], clf4['recall_sc'][0], clf4['recall_sc'][1], clf4['precision_sc'][0], clf4['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df4.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjENOg-VCmh8"
      },
      "source": [
        "## **GaussianNB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpRDh1urCmh8"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'var_smoothing': uniform(1e-9, 1e-6)}\n",
        "\n",
        "# Create the DecisionTreeClassifierr model\n",
        "clf5 = GaussianNB()\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf5, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVwL2jkFCmh8"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = GaussianNB(**random_search.best_params_)\n",
        "model5 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf5 = print_auc(model5, X_train, y_train, X_test, y_test, 'GaussianNB')\n",
        "df5 = pd.DataFrame(data=[['GaussianNB', clf5['f1'], clf5['auc'], clf5['auc_pr'], clf5['recall_sc'][0], clf5['recall_sc'][1], clf5['precision_sc'][0], clf5['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df5.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te1yJsQ5Cmh9"
      },
      "source": [
        "## **LGBMClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rn2bEFYCmh9"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'num_leaves': randint(10, 30),\n",
        "              'max_depth': randint(3, 10),\n",
        "              'learning_rate': uniform(1e-5, 1),\n",
        "              'n_estimators': randint(50, 200),\n",
        "              'min_child_samples': randint(10, 30),\n",
        "              'subsample': uniform(0.8, 1),\n",
        "              'colsample_bytree': uniform(0.8, 1),\n",
        "              'class_weight' : ['balanced', None, class_weights]}\n",
        "\n",
        "# Create the LGBMClassifier model\n",
        "clf6 = lgb.LGBMClassifier()\n",
        "         \n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf6, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7PAH5E7Cmh9"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = lgb.LGBMClassifier(**random_search.best_params_)\n",
        "model6 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf6 = print_auc(model6, X_train, y_train, X_test, y_test, 'LGBMClassifier')\n",
        "df6 = pd.DataFrame(data=[['LGBMClassifier', clf6['f1'], clf6['auc'], clf6['auc_pr'], clf6['recall_sc'][0], clf6['recall_sc'][1], clf6['precision_sc'][0], clf6['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df6.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlLkfuG5Cmh9"
      },
      "source": [
        "## **KNeighborsClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQOHgA__Cmh9"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'n_neighbors': randint(3, 7),\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'p': [1, 2],\n",
        "              'algorithm': ['brute'],\n",
        "              'leaf_size': randint(10, 50)}\n",
        "\n",
        "# Create the KNeighborsClassifier model\n",
        "clf7 = KNeighborsClassifier()\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf7, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUjyf7CICmh-"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = KNeighborsClassifier(**random_search.best_params_)\n",
        "model7 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf7 = print_auc(model7, X_train, y_train, X_test, y_test, 'KNeiborsClassifier')\n",
        "df7 = pd.DataFrame(data=[['KNeiborsClassifier', clf7['f1'], clf7['auc'], clf7['auc_pr'], clf7['recall_sc'][0], clf7['recall_sc'][1], clf7['precision_sc'][0], clf7['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df7.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de8Nk078Cmh-"
      },
      "source": [
        "## **RandomForestClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXg14ztPCmh-"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'n_estimators': randint(50, 1000),\n",
        "              'max_depth': randint(3, 10),\n",
        "              'min_samples_split': randint(2, 10),\n",
        "              'min_samples_leaf': randint(1, 5),\n",
        "              'max_features': ['sqrt', 'log2', None],\n",
        "              'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "              'class_weight' : ['balanced', None, class_weights]}\n",
        "\n",
        "# Create the RandomForestClassifier model\n",
        "clf8 = RandomForestClassifier(random_state=seed)\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf8, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skDjjiAYCmh-"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = RandomForestClassifier(**random_search.best_params_, random_state=seed)\n",
        "model8 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf8 = print_auc(model8, X_train, y_train, X_test, y_test, 'RandomForestClassifier')\n",
        "df8 = pd.DataFrame(data=[['RandomForestClassifier', clf8['f1'], clf8['auc'], clf8['auc_pr'], clf8['recall_sc'][0], clf8['recall_sc'][1], clf8['precision_sc'][0], clf8['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df8.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaF23HIECmh-"
      },
      "source": [
        "## **SVC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMDdzllRCmh-"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'C': uniform(0.1, 100),\n",
        "              'degree': randint(2, 5),\n",
        "              'gamma': ['scale', 'auto'],\n",
        "              'class_weight': [None, 'balanced', class_weights]}\n",
        "\n",
        "# Create the SVC model\n",
        "clf9 = SVC(probability=True)              \n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf9, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=50, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ie-sTi9Cmh_"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = SVC(**random_search.best_params_, probability=True)\n",
        "model9 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf9 = print_auc(model9, X_train, y_train, X_test, y_test, 'SVM')\n",
        "df9 = pd.DataFrame(data=[['SVM', clf9['f1'], clf9['auc'], clf9['auc_pr'], clf9['recall_sc'][0], clf9['recall_sc'][1], clf9['precision_sc'][0], clf9['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df9.style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehGoNxhhCmh_"
      },
      "source": [
        "## **LogisticRegression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB2yWtzyCmh_"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "param_dist = {'penalty': ['l1', 'l2'],\n",
        "              'C': uniform(0.1, 100),\n",
        "              'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag'],\n",
        "              'max_iter': randint(100, 500),\n",
        "              'class_weight': [None, 'balanced', class_weights]}\n",
        "\n",
        "# Create the LogisticRegressionr model\n",
        "clf10 = LogisticRegression()\n",
        "\n",
        "# Create the randomized search object\n",
        "random_search = RandomizedSearchCV(estimator=clf10, param_distributions=param_dist, n_iter=100, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search object to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(random_search.best_params_)\n",
        "best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d556VjRjCmh_"
      },
      "outputs": [],
      "source": [
        "# Use the best hyperparameters to fit the model to the training data\n",
        "clf_best = LogisticRegression(**random_search.best_params_, random_state=seed)\n",
        "model10 = clf_best.fit(X_train, y_train)\n",
        "\n",
        "clf10 = print_auc(model10, X_train, y_train, X_test, y_test, 'LogisticRegression')\n",
        "df10 = pd.DataFrame(data=[['LogisticRegression', clf10['f1'], clf10['auc'], clf10['auc_pr'], clf10['recall_sc'][0], clf10['recall_sc'][1], clf10['precision_sc'][0], clf10['precision_sc'][1]]], \n",
        "                          columns=['model', 'f1_score', 'auc', 'auc_pr', 'recall_classe(0)', 'recall_classe(1)', 'precision_classe(0)', 'precision_classe(1)'])\n",
        "df10.style.hide_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdHUU51eCmiA"
      },
      "outputs": [],
      "source": [
        "df_sm = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10]\n",
        "df_finale_sm = pd.concat(df_sm)\n",
        "df_finale_sm.style.hide_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvv28YesCmiA"
      },
      "outputs": [],
      "source": [
        "df_finale_sm.to_csv('df_finale_sm.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8ujQpQYCmiA"
      },
      "outputs": [],
      "source": [
        "smote_ = best_params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [16, 8]\n",
        "plt.plot(clf6[\"fpr\"], clf6[\"tpr\"], label=\"LGBMClassifier, auc=\"+str(clf10[\"auc\"]))\n",
        "plt.plot(clf9[\"fpr\"], clf9[\"tpr\"], label=\"SVM, auc=\"+str(clf2[\"auc\"]))\n",
        "plt.plot(clf5[\"fpr\"], clf5[\"tpr\"], label=\"GaussianNB, auc=\"+str(clf3[\"auc\"]))\n",
        "plt.plot(clf1[\"fpr\"], clf1[\"tpr\"], label=\"ExtraTrees, auc=\"+str(clf6[\"auc\"]))\n",
        "plt.plot(clf7[\"fpr\"], clf7[\"tpr\"], label=\"KNN, auc=\"+str(clf5[\"auc\"]))\n",
        "plt.plot(clf4[\"fpr\"], clf4[\"tpr\"], label=\"DT, auc=\"+str(clf8[\"auc\"]))\n",
        "plt.plot(clf10[\"fpr\"], clf10[\"tpr\"], label=\"LR, auc=\"+str(clf9[\"auc\"]))\n",
        "plt.plot(clf8[\"fpr\"], clf8[\"tpr\"], label=\"RF, auc=\"+str(clf4[\"auc\"]))\n",
        "plt.plot(clf3[\"fpr\"], clf3[\"tpr\"], label=\"AdaBoost, auc=\"+str(clf7[\"auc\"]))\n",
        "plt.plot(clf2[\"fpr\"], clf2[\"tpr\"], label=\"XGB, auc=\"+str(clf2[\"auc\"]))\n",
        "\n",
        "plt.xlabel(\"tpr\")\n",
        "plt.ylabel(\"fpr\")\n",
        "plt.legend(loc=4)\n",
        "plt.savefig('smote_data.png', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wJiUy-HVSC1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}